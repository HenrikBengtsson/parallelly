[{"path":[]},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported project lead. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://parallelly.futureverse.org/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to the ‘parallelly’ package","title":"Contributing to the ‘parallelly’ package","text":"Git repository uses Git Flow branching model (git flow extension useful ). develop branch contains latest contributions code appear next release, master branch contains code latest release, exactly currently CRAN. Contributing package easy. Just send pull request. send PR, make sure develop destination branch parallelly repository. PR pass R CMD check ---cran, also checked GitHub Actions PR submitted. abide Code Conduct Contributor Covenant.","code":""},{"path":"https://parallelly.futureverse.org/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Henrik Bengtsson. Author, maintainer, copyright holder.","code":""},{"path":"https://parallelly.futureverse.org/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bengtsson H (2022). parallelly: Enhancing 'parallel' Package. https://parallelly.futureverse.org, https://github.com/HenrikBengtsson/parallelly.","code":"@Manual{,   title = {parallelly: Enhancing the 'parallel' Package},   author = {Henrik Bengtsson},   year = {2022},   note = {https://parallelly.futureverse.org, https://github.com/HenrikBengtsson/parallelly}, }"},{"path":"https://parallelly.futureverse.org/index.html","id":"parallelly-enhancing-the-parallel-package-","dir":"","previous_headings":"","what":"Enhancing the parallel Package","title":"Enhancing the parallel Package","text":"parallelly package provides functions enhance parallel packages. example, availableCores() gives number CPU cores available R process given R options environment variables, including set job schedulers high-performance compute (HPC) clusters. R runs ‘cgroups’ Linux container, settings acknowledges . nothing else set, fall back parallel::detectCores(). Another example makeClusterPSOCK(), backward compatible parallel::makePSOCKcluster() better job setting remote cluster workers without know local public IP address configuring firewall port-forwarding local computer. functions features added package written backward compatible parallel package, may incorporated later. parallelly package comes open invitation R Core Team adopt parts code parallel package.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/index.html","id":"compatibility-with-the-parallel-package","dir":"","previous_headings":"","what":"Compatibility with the parallel package","title":"Enhancing the parallel Package","text":"cluster created parallelly package fully compatible clusters created parallel package can used parallel’s functions cluster processing, e.g. parallel::clusterEvalQ() parallel::parLapply(). parallelly::makeClusterPSOCK() function can used stand-replacement parallel::makePSOCKcluster(), equivalently, parallel::makeCluster(..., type = \"PSOCK\"). parallelly functions apply also clusters created parallel package. example, makes cluster created parallel shut automatically R’s garbage collector removes cluster object. lowers risk leaving stray R worker processes running background mistake. Another way achieve single call use:","code":"cl <- parallel::makeCluster(2) cl <- parallelly::autoStopCluster(cl) cl <- parallelly::makeClusterPSOCK(2, autoStop = TRUE)"},{"path":"https://parallelly.futureverse.org/index.html","id":"availablecores-vs-paralleldetectcores","dir":"","previous_headings":"Compatibility with the parallel package","what":"availableCores() vs parallel::detectCores()","title":"Enhancing the parallel Package","text":"availableCores() function designed better, safer alternative detectCores() parallel package. designed worry-free solution developers end-users query number available cores - solution plays nice multi-tenant systems, high-performance compute (HPC) cluster, CRAN check servers, elsewhere. know parallel::detectCores() might return NA systems, parallel::detectCores() - 1 might return 0 systems, e.g. old hardware virtual machines? , use max(1, parallel::detectCores() - 1, na.rm = TRUE) get correct. contrast, parallelly::availableCores() guaranteed return positive integer, can use parallelly::availableCores(omit = 1) return one core always least 1. Just like software tools “hijacks” cores default, R scripts, packages defaults detectCores() number parallel workers cause lots suffering fellow end-users system administrators. instance, shared server 48 cores come halt already users run parallel processing using detectCores() number parallel workers. problem gets worse machines many cores can host even concurrent users. R users used availableCores() instead, system administrator can limit number cores user get , say, 2, setting environment variable R_PARALLELLY_AVAILABLECORES_FALLBACK=2. contrast, possible override parallel::detectCores() returns, cf. PR#17641 - WISH: Make parallel::detectCores() agile new env var R_DEFAULT_CORES. time, HPC cluster job scheduler, script uses availableCores() run number parallel workers job scheduler assigned job. example, submit Slurm job sbatch --cpus-per-task=16 ..., availableCores() return 16 respects SLURM_* environment variables set scheduler. See help(\"availableCores\", package = \"parallelly\") currently supported job schedulers. Besides job schedulers, availableCores() respects R options environment variables commonly used specify number parallel workers, e.g. R option mc.cores. detect running R CMD check return 2, maximum number parallel workers allowed CRAN Policies. nothing set limits number cores, availableCores() falls back parallel::detectCores() returns NA_integer_ 1 returned. table summarize benefits:","code":""},{"path":"https://parallelly.futureverse.org/index.html","id":"backward-compatibility-with-the-future-package","dir":"","previous_headings":"","what":"Backward compatibility with the future package","title":"Enhancing the parallel Package","text":"functions package originate future package used validated several years. moved functions separate package, also useful outside future framework. backward-compatibility reasons future framework, R options environment variables prefixed parallelly.* R_PARALLELLY_* can time also set future.* R_FUTURE_* prefixes.","code":""},{"path":"https://parallelly.futureverse.org/index.html","id":"roadmap","dir":"","previous_headings":"","what":"Roadmap","title":"Enhancing the parallel Package","text":"Submit parallelly CRAN, minimal changes compared corresponding functions future package (CRAN 2020-10-20) Update future package import re-export functions parallelly maximize backward compatibility future framework (future 1.20.1 CRAN 2020-11-03) Switch use 10-15% faster useXDR=FALSE Implement fast parallel setup parallel PSOCK workers parallel (>= 4.0.0) validated negative impact future framework, allow changes parallelly package, e.g. renaming R options environment variable parallelly.* R_PARALLELLY_* falling back future.* R_FUTURE_* Migrate, currently internal, UUID functions export , e.g. uuid(), connectionUuid(), sessionUuid() (https://github.com/HenrikBengtsson/Wishlist--R/issues/96). R built-md5 checksum function operates object, functions require us adding dependency digest package. Add vignettes set cluster running local remote machines, including Linux containers popular cloud services, vignettes common problems troubleshoot Initially, backward compatibility future package top priority.","code":""},{"path":"https://parallelly.futureverse.org/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Enhancing the parallel Package","text":"R package parallelly available CRAN can installed R :","code":"install.packages(\"parallelly\")"},{"path":"https://parallelly.futureverse.org/index.html","id":"pre-release-version","dir":"","previous_headings":"Installation","what":"Pre-release version","title":"Enhancing the parallel Package","text":"install pre-release version available Git branch develop GitHub, use: install package source.","code":"remotes::install_github(\"HenrikBengtsson/parallelly\", ref=\"develop\")"},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce an Object to a Cluster Object — as.cluster","title":"Coerce an Object to a Cluster Object — as.cluster","text":"Coerce Object Cluster Object","code":""},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce an Object to a Cluster Object — as.cluster","text":"","code":"as.cluster(x, ...)  # S3 method for cluster as.cluster(x, ...)  # S3 method for list as.cluster(x, ...)  # S3 method for SOCKnode as.cluster(x, ...)  # S3 method for SOCK0node as.cluster(x, ...)  # S3 method for cluster c(..., recursive = FALSE)"},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce an Object to a Cluster Object — as.cluster","text":"x object coerced. ... Additional arguments passed underlying coercion method. c(...), clusters cluster nodes combined. recursive used.","code":""},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce an Object to a Cluster Object — as.cluster","text":"object class cluster. c(...) combine multiple clusters / cluster nodes one cluster returned class cluster.  warning produced duplicated nodes resulting cluster.","code":""},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce an Object to a Cluster Object — as.cluster","text":"","code":"cl1 <- makeClusterPSOCK(2, dryrun = TRUE) #> ---------------------------------------------------------------------- #> Manually, start worker #1 on local machine ‘localhost’ with: #>  #>   '/home/hb/software/R-devel/R-4-1-branch/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> ---------------------------------------------------------------------- #> Manually, start worker #2 on local machine ‘localhost’ with: #>  #>   '/home/hb/software/R-devel/R-4-1-branch/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  cl2 <- makeClusterPSOCK(c(\"n1\", \"server.remote.org\"), dryrun = TRUE) #> ---------------------------------------------------------------------- #> Manually, (i) login into external machine ‘n1’: #>  #>   '/usr/bin/ssh' -R 11000:localhost:11000 n1 #>  #> and (ii) start worker #1 from there: #>  #>   '/home/hb/software/R-devel/R-4-1-branch/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> Alternatively, start worker #1 from the local machine by combining both step in a single call: #>  #>   '/usr/bin/ssh' -R 11000:localhost:11000 n1 \"'/home/hb/software/R-devel/R-4-1-branch/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \\\"no-delay\\\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential\" #>  #> ---------------------------------------------------------------------- #> Manually, (i) login into external machine ‘server.remote.org’: #>  #>   '/usr/bin/ssh' -R 11001:localhost:11000 server.remote.org #>  #> and (ii) start worker #2 from there: #>  #>   'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11001 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> Alternatively, start worker #2 from the local machine by combining both step in a single call: #>  #>   '/usr/bin/ssh' -R 11001:localhost:11000 server.remote.org \"'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \\\"no-delay\\\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11001 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential\" #>  cl <- c(cl1, cl2) #> Warning: The combined cluster contains 1 duplicated nodes print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host ‘NA’ (R version and platform not queried)"},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"Registers finalizer cluster cluster stopped garbage collected","code":""},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"","code":"autoStopCluster(cl, debug = FALSE)"},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"cl cluster object created instance makeClusterPSOCK() parallel::makeCluster(). debug TRUE, debug messages produced cluster garbage collected.","code":""},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"cluster object attribute gcMe set.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"","code":"cl <- makeClusterPSOCK(2, dryrun = TRUE) #> ---------------------------------------------------------------------- #> Manually, start worker #1 on local machine ‘localhost’ with: #>  #>   '/home/hb/software/R-devel/R-4-1-branch/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> ---------------------------------------------------------------------- #> Manually, start worker #2 on local machine ‘localhost’ with: #>  #>   '/home/hb/software/R-devel/R-4-1-branch/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions = \"no-delay\")' -e 'workRSOCK <- tryCatch(parallel:::.workRSOCK, error=function(e) parallel:::.slaveRSOCK); workRSOCK()' MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  cl <- autoStopCluster(cl) print(cl) #> Socket cluster with 1 nodes where 1 node is on host ‘NA’ (R version and platform not queried). This cluster is registered to be automatically stopped by the garbage collector rm(list = \"cl\") gc() #>           used (Mb) gc trigger (Mb) max used (Mb) #> Ncells  855545 45.7    1379521 73.7  1379521 73.7 #> Vcells 1588255 12.2    8388608 64.0  2429400 18.6"},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Available and Free Connections — availableConnections","title":"Number of Available and Free Connections — availableConnections","text":"number connections can open time R typically 128, first three occupied always open stdin(), stdout(), stderr() connections, leaves 125 slots available types connections.  Connections used many places, e.g. reading writing file, downloading URLs, communicating parallel R processes socket connections, capturing standard output via text connections.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Available and Free Connections — availableConnections","text":"","code":"availableConnections()  freeConnections()"},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Available and Free Connections — availableConnections","text":"non-negative integer, +Inf available number connections greated 16384, limit set via option parallelly.availableConnections.tries.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"how-to-increase-the-limit","dir":"Reference","previous_headings":"","what":"How to increase the limit","title":"Number of Available and Free Connections — availableConnections","text":"limit 128 connections can changed rebuilding R source.  limited hardcoded  src/main/connections.c.","code":"#define NCONNECTIONS 128"},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"how-the-limit-is-identified","dir":"Reference","previous_headings":"","what":"How the limit is identified","title":"Number of Available and Free Connections — availableConnections","text":"Since limit might changed, instance custom R builds future releases R, want assume limit 128 R installation.  Unfortunately, possible query R limit . Instead, availableConnections() infers trial--error. fails.  efficiency, result memoized throughout current R session.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Number of Available and Free Connections — availableConnections","text":"'WISH: Increase limit maximum number open connections (currently 125+3)', 2016-07-09, https://github.com/HenrikBengtsson/Wishlist--R/issues/28","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Available and Free Connections — availableConnections","text":"","code":"total <- availableConnections() message(\"You can have \", total, \" connections open in this R installation\") #> You can have 128 connections open in this R installation free <- freeConnections() message(\"There are \", free, \" connections remaining\") #> There are 124 connections remaining"},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Number of Available Cores on The Current Machine — availableCores","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"current/main R session counts one, meaning minimum number cores available always least one.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"","code":"availableCores(   constraints = NULL,   methods = getOption2(\"parallelly.availableCores.methods\", c(\"system\", \"nproc\",     \"mc.cores\", \"BiocParallel\", \"_R_CHECK_LIMIT_CORES_\", \"PBS\", \"SGE\", \"Slurm\", \"LSF\",     \"fallback\", \"custom\")),   na.rm = TRUE,   logical = getOption2(\"parallelly.availableCores.logical\", TRUE),   default = c(current = 1L),   which = c(\"min\", \"max\", \"all\"),   omit = getOption2(\"parallelly.availableCores.omit\", 0L) )"},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"constraints optional character specifying constraints (\"purposes\") requesting values. instance, systems multicore processing supported (.e. Windows), using constrains = \"multicore\" force single core reported. methods character vector specifying infer number available cores. na.rm TRUE, non-missing settings considered/returned. logical Passed detectCores(logical = logical), , supported, returns number logical CPUs (TRUE) physical CPUs/cores (FALSE). argument argument methods includes \"system\". default default number cores return non-missing settings available. character specifying settings return. \"min\" (default), minimum value returned. \"max\", maximum value returned (careful!) \"\", values returned. omit (integer; non-negative) Number cores include.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"Return positive (>= 1) integer. = \"\", one value may returned. Together na.rm = FALSE missing values may also returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"following settings (\"methods\") inferring number cores supported: \"system\" - Query detectCores(logical = logical). \"nproc\" - Unix, query system command nproc. \"mc.cores\" - available, returns value option mc.cores. Note mc.cores defined number additional R processes can used addition main R process.  means mc.cores = 0 calculations done main R process, .e. exactly one core available calculations. mc.cores option defaults environment variable MC_CORES (set accordingly parallel package loaded).  mc.cores option used instance mclapply() parallel package. \"BiocParallel\" - Query environment variables BIOCPARALLEL_WORKER_NUMBER (integer), defined used BiocParallel (>= 1.27.2), BBS_HOME (logical) used Bioconductor Build System. former set, number cores considered.  latter set, maximum 4 cores considered. \"PBS\" - Query TORQUE/PBS environment variables PBS_NUM_PPN NCPUS. Depending PBS system configuration, resource parameters may may default one. example job submission results qsub -l nodes=1:ppn=2, requests one node two cores. \"SGE\" - Query Sun/Oracle Grid Engine (SGE) environment variable NSLOTS. example job submission results qsub -pe smp 2 (qsub -pe by_node 2), requests two cores single machine. \"Slurm\" - Query Simple Linux Utility Resource Management (Slurm) environment variable SLURM_CPUS_PER_TASK. may may set.  can set submitting job, e.g. sbatch --cpus-per-task=2 hello.sh adding #SBATCH --cpus-per-task=2 hello.sh script. SLURM_CPUS_PER_TASK set, fall back use SLURM_CPUS_ON_NODE job single-node job (SLURM_JOB_NUM_NODES 1), e.g. sbatch --ntasks=2 hello.sh. \"LSF\" - Query Platform Load Sharing Facility (LSF) environment variable LSB_DJOB_NUMPROC. Jobs multiple (CPU) slots can submitted LSF using bsub -n 2 -R \"span[hosts=1]\" < hello.sh. \"custom\" - option parallelly.availableCores.custom set function, function called (without arguments) value coerced integer, interpreted number available cores.  value NA, ignored. value methods element, R option name queried.  set, system environment variable queried.  neither set, missing value returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"avoid-ending-up-with-zero-cores","dir":"Reference","previous_headings":"","what":"Avoid ending up with zero cores","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"Note machines might limited number cores, R process runs container cgroup provides small number cores.  cases:  may return zero, often intended likely give error downstream.  Instead, use:  put aside one cores used.  Regardless many cores put aside, function guaranteed return least one core.","code":"ncores <- availableCores() - 1 ncores <- availableCores(omit = 1)"},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"advanced-usage","dir":"Reference","previous_headings":"","what":"Advanced usage","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"possible override maximum number cores machine reported availableCores(methods = \"system\").  can done first specifying options(parallelly.availableCores.methods = \"mc.cores\") number cores use, e.g. options(mc.cores = 8).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"","code":"message(paste(\"Number of cores available:\", availableCores())) #> Number of cores available: 8  if (FALSE) { options(mc.cores = 2L) message(paste(\"Number of cores available:\", availableCores())) }  if (FALSE) { ## IMPORTANT: availableCores() may return 1L options(mc.cores = 1L) ncores <- availableCores() - 1      ## ncores = 0 ncores <- availableCores(omit = 1)  ## ncores = 1 message(paste(\"Number of cores to use:\", ncores)) }  if (FALSE) { ## Use 75% of the cores on the system but never more than four options(parallelly.availableCores.custom = function() {   ncores <- max(parallel::detectCores(), 1L, na.rm = TRUE)   ncores <- min(as.integer(0.75 * ncores), 4L)   max(1L, ncores) }) message(paste(\"Number of cores available:\", availableCores()))  ## What is available minus one core but at least one options(parallelly.availableCores.custom = function() {   max(1L, parallelly::availableCores() - 1L) }) message(paste(\"Number of cores available:\", availableCores())) }"},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Set of Available Workers — availableWorkers","title":"Get Set of Available Workers — availableWorkers","text":"Get Set Available Workers","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Set of Available Workers — availableWorkers","text":"","code":"availableWorkers(   methods = getOption2(\"parallelly.availableWorkers.methods\", c(\"mc.cores\",     \"BiocParallel\", \"_R_CHECK_LIMIT_CORES_\", \"PBS\", \"SGE\", \"Slurm\", \"LSF\", \"custom\",     \"system\", \"fallback\")),   na.rm = TRUE,   logical = getOption2(\"parallelly.availableCores.logical\", TRUE),   default = getOption2(\"parallelly.localhost.hostname\", \"localhost\"),   which = c(\"auto\", \"min\", \"max\", \"all\") )"},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Set of Available Workers — availableWorkers","text":"methods character vector specifying infer number available cores. na.rm TRUE, non-missing settings considered/returned. logical Passed -availableCores(). default default set workers. character specifying set / sets return. \"auto\" (default), first non-empty set found. \"min\", minimum value returned. \"max\", maximum value returned (careful!) \"\", values returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Set of Available Workers — availableWorkers","text":"Return character vector workers, typically consists names machines / compute nodes, may also IP numbers.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Set of Available Workers — availableWorkers","text":"default set workers method rep(\"localhost\", times = availableCores(methods = method, logical = logical)), means least use many parallel workers current machine availableCores() allows method. addition, following settings (\"methods\") also acknowledged: \"PBS\" - Query TORQUE/PBS environment variable PBS_NODEFILE. set specifies existing file, set workers read file, one worker (node) given per line. example job submission results qsub -l nodes = 4:ppn = 2, requests four nodes two cores. \"SGE\" - Query Sun/Oracle Grid Engine (SGE) environment variable PE_HOSTFILE. example job submission results qsub -pe mpi 8 (qsub -pe ompi 8), requests eight cores number machines. \"LSF\" - Query LSF/OpenLava environment variable LSB_HOSTS. \"Slurm\" - Query Slurm environment variable SLURM_JOB_NODELIST (fallback legacy SLURM_NODELIST) parse set nodes. query Slurm environment variable SLURM_JOB_CPUS_PER_NODE (fallback SLURM_TASKS_PER_NODE) infer many CPU cores Slurm alloted nodes.  SLURM_CPUS_PER_TASK set, always scalar, respected , .e. smaller, used nodes. example, SLURM_NODELIST=\"n1,n[03-05]\" (expands c(\"n1\", \"n03\", \"n04\", \"n05\")) SLURM_JOB_CPUS_PER_NODE=\"2(x2),3,2\" (expands c(2, 2, 3, 2, 2)), c(\"n1\", \"n1\", \"n03\", \"n03\", \"n04\", \"n04\", \"n04\", \"n05\", \"n05\") returned.  addition, SLURM_CPUS_PER_TASK=1, can happen depending hyperthreading configurations Slurm cluster, c(\"n1\", \"n03\", \"n04\", \"n05\") returned. \"custom\" - option parallelly.availableWorkers.custom set function, function called (without arguments) value coerced character vector, interpreted hostnames available workers.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"known-limitations","dir":"Reference","previous_headings":"","what":"Known limitations","title":"Get Set of Available Workers — availableWorkers","text":"availableWorkers(methods = \"Slurm\") expand SLURM_JOB_NODELIST using scontrol show hostnames \"$SLURM_JOB_NODELIST\", available. available, attempts parse compressed nodelist based best-guess understanding possible syntax may . One known limitation \"multi-dimensional\" ranges supported, e.g. \"[1-2]b[3-4]\" expanded scontrol c(\"a1b3\", \"a1b4\", \"a2b3\", \"a2b4\").  scontrol available, components failed parsed dropped informative warning message.  compents parsed, result methods = \"Slurm\" empty.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Set of Available Workers — availableWorkers","text":"","code":"message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) #> Available workers: ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’  if (FALSE) { options(mc.cores = 2L) message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) }  if (FALSE) { ## Always use two workers on host 'n1' and one on host 'n2' options(parallelly.availableWorkers.custom = function() {   c(\"n1\", \"n1\", \"n2\") }) message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) }"},{"path":"https://parallelly.futureverse.org/reference/canPortBeUsed.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether a TCP port can be opened or not — canPortBeUsed","title":"Check whether a TCP port can be opened or not — canPortBeUsed","text":"Check whether TCP port can opened ","code":""},{"path":"https://parallelly.futureverse.org/reference/canPortBeUsed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether a TCP port can be opened or not — canPortBeUsed","text":"","code":"canPortBeUsed(port)"},{"path":"https://parallelly.futureverse.org/reference/canPortBeUsed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether a TCP port can be opened or not — canPortBeUsed","text":"port (integer) TCP port [0, 65535].","code":""},{"path":"https://parallelly.futureverse.org/reference/canPortBeUsed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether a TCP port can be opened or not — canPortBeUsed","text":"canPortBeUsed(port) returns logical indicating whether port can opened , queried.  port can opened, TRUE returned, opened FALSE returned, may happen port used another process. port querying supported, R (< 4.0.0),  NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Recent CPU Load — cpuLoad","title":"Get the Recent CPU Load — cpuLoad","text":"Get Recent CPU Load","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Recent CPU Load — cpuLoad","text":"","code":"cpuLoad()"},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Recent CPU Load — cpuLoad","text":"named numeric vector three elements 1min, 5min, 15min non-negative values. values represent estimates CPU load last minute, last five minutes, last fifteen minutes [1]. idle system values close zero, heavily loaded system values near parallel::detectCores(). unknown, missing values returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the Recent CPU Load — cpuLoad","text":"function works Unix-like system /proc/loadavg.","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get the Recent CPU Load — cpuLoad","text":"Linux Load Averages: Solving Mystery, Brendan Gregg's Blog, 2017-08-08, http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Recent CPU Load — cpuLoad","text":"","code":"loadavg <- cpuLoad() print(loadavg) #>  1min  5min 15min  #>  0.87  0.65  0.57"},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for SSH clients on the current system — find_rshcmd","title":"Search for SSH clients on the current system — find_rshcmd","text":"Search SSH clients current system","code":""},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for SSH clients on the current system — find_rshcmd","text":"","code":"find_rshcmd(which = NULL, first = FALSE, must_work = TRUE)"},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for SSH clients on the current system — find_rshcmd","text":"character vector specifying types SSH clients search .  NULL, default set clients supported current platform searched . first TRUE, first client found returned, otherwise located clients returned. must_work TRUE clients found, error produced, otherwise warning.","code":""},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for SSH clients on the current system — find_rshcmd","text":"named list pathnames located SSH clients. pathnames may followed zero command-line options, .e. elements returned list character vectors length one . first = TRUE, first one returned. Attribute version contains output querying executable version (via command-line option -V).","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Average Number of Free CPU Cores — freeCores","title":"Get the Average Number of Free CPU Cores — freeCores","text":"Get Average Number Free CPU Cores","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Average Number of Free CPU Cores — freeCores","text":"","code":"freeCores(   memory = c(\"5min\", \"15min\", \"1min\"),   fraction = 0.9,   logical = getOption2(\"parallelly.availableCores.logical\", TRUE),   default = parallelly::availableCores() )"},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Average Number of Free CPU Cores — freeCores","text":"memory (character) time period used infer system load, alternatives 5 minutes (default), 15 minutes, 1 minute. fraction (non-negative numeric) scale factor. logical Passed -availableCores(). default (integer) value returned system load unknown, .e. cpuLoad() return missing values.","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Average Number of Free CPU Cores — freeCores","text":"positive integer attributes loadavg (named numeric), maxCores (named integer), argument memory (character), argument fraction (numeric).","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Average Number of Free CPU Cores — freeCores","text":"","code":"free <- freeCores() print(free) #> [1] 6 #> attr(,\"loadavg\") #>  1min  5min 15min  #>  0.87  0.65  0.57  #> attr(,\"maxCores\") #> system  #>      8  #> attr(,\"memory\") #> [1] \"5min\" #> attr(,\"fraction\") #> [1] 0.9  if (FALSE) { ## Make availableCores() agile to the system load options(parallelly.availableCores.custom = function() freeCores()) }"},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a TCP port that can be opened — freePort","title":"Find a TCP port that can be opened — freePort","text":"Find TCP port can opened","code":""},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a TCP port that can be opened — freePort","text":"","code":"freePort(ports = 1024:65535, default = \"random\", randomize = TRUE)"},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find a TCP port that can be opened — freePort","text":"ports (integer vector, character string) Zero TCP ports [0, 65535] scan. \"random\", random set ports considered. \"auto\", port given environment variable R_PARALLEL_PORT used, may also specify random. default (integer) NA_integer_ port returned available port found. \"first\", ports[1].  \"random\", random port among ports used. length(ports) == 0, NA_integer_. randomize (logical) TRUE, ports randomly shuffled searched.  shuffle forward RNG seed.","code":""},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find a TCP port that can be opened — freePort","text":"Returns integer representing first port among ports can opened.  none can opened, default returned. port querying supported, R (< 4.0.0), defaultis returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/getOption2.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets an R Option or an Environment Variable — getOption2","title":"Gets an R Option or an Environment Variable — getOption2","text":"Gets R Option Environment Variable","code":""},{"path":"https://parallelly.futureverse.org/reference/getOption2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets an R Option or an Environment Variable — getOption2","text":"","code":"getOption2(name, default = NULL)"},{"path":"https://parallelly.futureverse.org/reference/getOption2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets an R Option or an Environment Variable — getOption2","text":"name (character string) name R option. default (single object) value returned neither R option environment variable set.  environment variable set, value coerced type default. envvar (character string) name environment variable. set, NULL, name automatically constructed upper-case version argument name periods (.) substituted underscores (_) prefixed R_, e.g. \"abc.debug\" becomes R_ABC_DEBUG.","code":""},{"path":"https://parallelly.futureverse.org/reference/getOption2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets an R Option or an Environment Variable — getOption2","text":"Returns object.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if a Connection is Valid — isConnectionValid","title":"Checks if a Connection is Valid — isConnectionValid","text":"Get unique identifier R connection check whether connection still valid.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if a Connection is Valid — isConnectionValid","text":"","code":"isConnectionValid(con)  connectionId(con)"},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if a Connection is Valid — isConnectionValid","text":"con connection.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks if a Connection is Valid — isConnectionValid","text":"isConnectionValid() returns TRUE connection still valid, otherwise FALSE.  FALSE, character attribute reason provides explanation connection valid. connectionId() returns non-negative integer, -1, NA_integer_. connections stdin, stdout, stderr, 0, 1, 2, returned, respectively.  connections, integer greater equal 3 based connection's internal pointer returned. connection serialized, longer valid, identifier -1. Attribute raw_id returns pointer string inferred.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"connection-index-versus-connection-identifier","dir":"Reference","previous_headings":"","what":"Connection Index versus Connection Identifier","title":"Checks if a Connection is Valid — isConnectionValid","text":"R represents connections indices using plain integers, e.g. idx <- .integer(con). three connections standard input (\"stdin\"), standard output (\"stdout\"), standard error (\"stderr\") always exists indices 0, 1, 2. connection opened beyond get index three greater, depending availability given base::showConnections(). get connection given index, use base::getConnection(). Unfortunately, index representation connections non-robust, e.g. cases two 'connection' objects can end index used, written output may end wrong destination files database might get corrupted.  can instance happen base::closeAllConnections() used (*). contrast, id <- connectionId(con) gives identifier unique 'connection' object.  identifier based internal pointer address object.  risk two connections R session end pointer address small. Thus, case ended situation two connections con1 con2 share index - .integer(con1) == .integer(con2) - never share identifier - connectionId(con1) != connectionId(con2). , isConnectionValid() can used check one connections, , valid. (*) Note good reason calling closeAllConnections() called, great risk files get corrupted etc. See (1) examples details problem. think need use , much safer restart R guaranteed give working R session non-clashing connections. might also closeAllConnections() used base::sys.save.image() called, might happen R forced terminate.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"connections-cannot-be-serialized-or-saved","dir":"Reference","previous_headings":"","what":"Connections Cannot be Serialized Or Saved","title":"Checks if a Connection is Valid — isConnectionValid","text":"'connection' serialized, e.g. saved file read used another R session.  attempted, connection valid.  problem may occur parallel processing passing R object parallel worker processing, e.g. exported object may hold internal database connection longer valid worker. connection serialized, internal pointer address invalidated (set nil). cases, connectionId(con) returns -1 isConnectionValid(con) returns FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Checks if a Connection is Valid — isConnectionValid","text":"'BUG: connection object may become corrupt re-referenced another connection (PATCH)', 2018-10-30. R-devel thread PATCH: Asserting 'connection' used changed + R_GetConnection2(), 2018-10-31.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Checks if a Connection is Valid — isConnectionValid","text":"","code":"## R represents connections as plain indices as.integer(stdin())          ## int 0 #> [1] 0 as.integer(stdout())         ## int 1 #> [1] 3 as.integer(stderr())         ## int 2 #> [1] 2  ## The first three connections always exist and are always valid isConnectionValid(stdin())   ## TRUE #> [1] TRUE connectionId(stdin())        ## 0L #> [1] 0 isConnectionValid(stdout())  ## TRUE #> [1] FALSE #> attr(,\"reason\") #> [1] \"Connection (connection: index=3, description=\\\"output\\\", class=\\\"textConnection\\\", mode=\\\"wr\\\", text=\\\"text\\\", opened=\\\"opened\\\", can read=\\\"no\\\", can write=\\\"yes\\\", id=NA) is no longer valid. It differ from the currently registered R connection with the same index 3 (connection: index=3, description=\\\"output\\\", class=\\\"textConnection\\\", mode=\\\"wr\\\", text=\\\"text\\\", opened=\\\"opened\\\", can read=\\\"no\\\", can write=\\\"yes\\\", id=1723, raw_id=\\\"<pointer: 0x6bb>\\\")\" connectionId(stdout())       ## 1L #> [1] NA isConnectionValid(stderr())  ## TRUE #> [1] TRUE connectionId(stderr())       ## 2L #> [1] 2  ## Connections cannot be serialized con <- file(tempfile(), open = \"w\") x <- list(value = 42, stderr = stderr(), con = con) y <- unserialize(serialize(x, connection = NULL)) isConnectionValid(y$stderr)  ## TRUE #> [1] TRUE connectionId(y$stderr)       ##  2L #> [1] 2 isConnectionValid(y$con)     ## FALSE with attribute 'reason' #> [1] FALSE #> attr(,\"reason\") #> [1] \"Connection (connection: index=4, description=\\\"/tmp/hb/RtmpxZwRVL/file24d52e750e50\\\", class=\\\"file\\\", mode=\\\"w\\\", text=\\\"text\\\", opened=\\\"opened\\\", can read=\\\"no\\\", can write=\\\"yes\\\", id=-1) is no longer valid. It differ from the currently registered R connection with the same index 4 (connection: index=4, description=\\\"/tmp/hb/RtmpxZwRVL/file24d52e750e50\\\", class=\\\"file\\\", mode=\\\"w\\\", text=\\\"text\\\", opened=\\\"opened\\\", can read=\\\"no\\\", can write=\\\"yes\\\", id=1729, raw_id=\\\"<pointer: 0x6c1>\\\")\" connectionId(y$con)          ## -1L #> [1] -1 close(con)"},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks whether or not we are running in a forked child process — isForkedChild","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"Checks whether running forked child process","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"","code":"isForkedChild()"},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"(logical) Returns TRUE running forked child process, otherwise FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"Examples setups functions rely forked parallelization parallel::makeCluster(n, type = \"FORK\"), parallel::mclapply(), future::plan(\"multicore\").","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"Checks whether Cluster Node Runs Forked Process","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"","code":"isForkedNode(node, ...)"},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"node cluster node class SOCKnode SOCK0node. ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"(logical) Returns TRUE cluster node running forked child process FALSE . inferred, NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"Checks whether Cluster Node Runs Localhost","code":""},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"","code":"isLocalhostNode(node, ...)"},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"node cluster node class SOCKnode SOCK0node. ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"(logical) Returns TRUE cluster node running current machine FALSE runs another machine. inferred, NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether or not the cluster nodes are alive — isNodeAlive","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"Check whether cluster nodes alive","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"","code":"isNodeAlive(x, ...)"},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"x cluster cluster node (\"worker\"). ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"logical vector length length(x) values FALSE, TRUE, NA.  can established process cluster node running, TRUE returned. run, FALSE returned. neither can inferred, instance worker runs remote machine, NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"function works checking whether cluster node process running .  done querying system process ID (PID), registered makeClusterPSOCK() node starts. PID known, NA returned. Unix macOS, PID queried using tools::pskill() fallback system(\"ps\"). MS Windows, system2(\"tasklist\") used, may take long time lot processes running. details, see internal pid_exists() function.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"","code":"# \\donttest{ cl <- makeClusterPSOCK(2)  ## Check if cluster nodes #2 is alive print(isNodeAlive(cl[[2]])) #> [1] TRUE  ## Check all nodes print(isNodeAlive(cl)) #> [1] TRUE TRUE # }"},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"makeClusterMPI() function creates MPI cluster R workers parallel processing.  function utilizes makeCluster(..., type = \"MPI\") parallel package tweaks cluster attempt avoid stopCluster() hanging (1). WARNING: function much beta version used parallel::makeCluster(..., type = \"MPI\") fails.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"","code":"makeClusterMPI(   workers,   ...,   autoStop = FALSE,   verbose = getOption2(\"parallelly.debug\", FALSE) )"},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"workers number workers (positive integer). ... Optional arguments passed makeCluster(workers, type = \"MPI\", ...). autoStop TRUE, cluster automatically stopped using stopCluster() garbage collected, unless already stopped.  See also autoStopCluster(). verbose TRUE, informative messages outputted.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"object class c(\"RichMPIcluster\", \"MPIcluster\", \"cluster\") consisting list \"MPInode\" workers.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"Creating MPI clusters requires Rmpi snow packages installed.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"R-sig-hpc thread Rmpi: mpi.close.Rslaves() 'hangs' 2017-09-28.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"","code":"if (FALSE) { if (requireNamespace(\"Rmpi\") && requireNamespace(\"snow\")) {   cl <- makeClusterMPI(2, autoStop = TRUE)   print(cl)   y <- parLapply(cl, X = 1:3, fun = sqrt)   print(y)   rm(list = \"cl\") } }"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"makeClusterPSOCK() function creates cluster R workers parallel processing.  R workers may background R sessions current machine, R sessions external machines (local remote), mix . external workers, default use SSH connect external machines.  function works similarly makePSOCKcluster() parallel package, provides additional flexibility options controlling setup system calls launch background R workers, connect external machines.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"","code":"makeClusterPSOCK(   workers,   makeNode = makeNodePSOCK,   port = c(\"auto\", \"random\"),   ...,   autoStop = FALSE,   tries = getOption2(\"parallelly.makeNodePSOCK.tries\", 3L),   delay = getOption2(\"parallelly.makeNodePSOCK.tries.delay\", 15),   validate = getOption2(\"parallelly.makeNodePSOCK.validate\", TRUE),   verbose = getOption2(\"parallelly.debug\", FALSE) )  makeNodePSOCK(   worker = getOption2(\"parallelly.localhost.hostname\", \"localhost\"),   master = NULL,   port,   connectTimeout = getOption2(\"parallelly.makeNodePSOCK.connectTimeout\", 2 * 60),   timeout = getOption2(\"parallelly.makeNodePSOCK.timeout\", 30 * 24 * 60 * 60),   rscript = NULL,   homogeneous = NULL,   rscript_args = NULL,   rscript_envs = NULL,   rscript_libs = NULL,   rscript_startup = NULL,   rscript_sh = c(\"auto\", \"cmd\", \"sh\"),   default_packages = c(\"datasets\", \"utils\", \"grDevices\", \"graphics\", \"stats\", if     (methods) \"methods\"),   methods = TRUE,   socketOptions = getOption2(\"parallelly.makeNodePSOCK.socketOptions\", \"no-delay\"),   useXDR = getOption2(\"parallelly.makeNodePSOCK.useXDR\", FALSE),   outfile = \"/dev/null\",   renice = NA_integer_,   rshcmd = getOption2(\"parallelly.makeNodePSOCK.rshcmd\", NULL),   user = NULL,   revtunnel = TRUE,   rshlogfile = NULL,   rshopts = getOption2(\"parallelly.makeNodePSOCK.rshopts\", NULL),   rank = 1L,   manual = FALSE,   dryrun = FALSE,   quiet = FALSE,   setup_strategy = getOption2(\"parallelly.makeNodePSOCK.setup_strategy\", \"parallel\"),   action = c(\"launch\", \"options\"),   verbose = FALSE )"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"workers hostnames workers (character vector) number localhost workers (positive integer). makeNode function creates \"SOCKnode\" \"SOCK0node\" object, represents connection worker. port port number master used communicating workers (via socket connections).  integer vector ports, random one among chosen.  \"random\", random port chosen 11000:11999, range specified environment variable R_PARALLELLY_RANDOM_PORTS. \"auto\" (default), default (single) port taken environment variable R_PARALLEL_PORT, otherwise \"random\" used. Note, use argument specify port number used rshcmd, typically SSH client.  Instead, SSH daemon runs different port default 22, specify SSH port appending hostname, e.g. \"remote.server.org:2200\" via SSH options -p, e.g. rshopts = c(\"-p\", \"2200\"). ... Optional arguments passed makeNode(workers[], ..., rank = ) = seq_along(workers). autoStop TRUE, cluster automatically stopped using stopCluster() garbage collected, unless already stopped.  See also autoStopCluster(). tries, delay Maximum number attempts done launch node makeNode() delay (seconds) -attempts. argument port specifies one port, e.g. port = \"random\" random port drawn validated tries times. Arguments tries delay used setup_strategy == \"sequential. validate TRUE (default), nodes created, validated work inquiring session information, saved attribute session_info node. verbose TRUE, informative messages outputted. worker hostname IP number machine worker run. master hostname IP number master / calling machine, known workers.  NULL (default), default Sys.info()[[\"nodename\"]] unless worker localhost revtunnel = TRUE case \"localhost\". connectTimeout maximum time (seconds) allowed socket connection master worker established (defaults 2 minutes). See note current lack support Linux macOS systems. timeout maximum time (seconds) allowed pass without master worker communicate (defaults 30 days). rscript, homogeneous system command launching Rscript worker whether installed path calling machine .  details, see . rscript_args Additional arguments Rscript (character vector).  argument can used customize R environment workers launches. instance, use rscript_args = c(\"-e\", shQuote('setwd(\"/path/\")')) set working directory /path/workers. rscript_envs named character vector environment variables set unset worker startup, e.g. rscript_envs = c(FOO = \"3.14\", \"HOME\", \"UNKNOWN\", UNSETME = NA_character_). element named, value variable used name value value Sys.getenv() variable.  Non-existing environment variables dropped. variables set using Sys.setenv(). named element value NA_character_ cause variable unset, done via Sys.unsetenv(). rscript_libs character vector R library paths used library search path R workers.  asterisk (\"*\") resolved default .libPaths() worker. , prepend folder, instead replacing existing ones, use rscript_libs = c(\"new_folder\", \"*\"). pass non-default library path currently set main R session workers, use rscript_libs = .libPaths(). rscript_startup R expression character vector R code, list mix , evaluated R worker prior launching worker's event loop. instance, use rscript_startup = 'setwd(\"/path/\")' set working directory /path/workers. rscript_sh type shell used rscript launched, \"sh\" launched via POSIX shell \"cmd\" launched via MS Windows shell.  controls shell command-line options quoted, via shQuote(..., type = rscript_sh). \"auto\" (default), cluster node launched locally, set \"sh\" \"cmd\" according current platform.  launched remotely, set \"sh\" based assumption remote machines typically launch commands via SSH POSIX shell. default_packages character vector NULL controls R packages attached cluster node startup.  asterisk (\"*\") resolves getOption(\"defaultPackages\") current machine. NULL, default set packages R attached. methods TRUE (default), methods package also loaded. argument exists legacy reasons due Rscript worked R (< 3.5.0). socketOptions character string sets R option socketOptions worker. useXDR FALSE (default), communication master workers, binary, use small-endian (faster), otherwise big-endian (\"XDR\"; slower). outfile direct stdout stderr connection output workers. NULL, redirection output done, means output relayed terminal local computer.  Windows, output relayed running R terminal GUI. renice numerical 'niceness' (priority) set worker processes. rshcmd, rshopts command (character vector) run master launch process another host additional arguments (character vector).  arguments applied machine localhost.  details, see . user (optional) user name used communicating another host. revtunnel TRUE, reverse SSH tunnel set worker worker R process sets socket connection local port (port - rank + 1) reaches master port port. FALSE, worker try connect directly port port master.  details, see . rshlogfile (optional) filename, output produced rshcmd call logged file, TRUE, logged temporary file.  log file name available attribute part return node object. Warning: works SSH clients support option -E .log.  example, PuTTY's plink support option, attempts specify rshlogfile cause SSH connection fail. rank unique one-based index worker (automatically set). manual TRUE workers need run manually. command run displayed. dryrun TRUE, nothing set , message suggesting launch worker terminal outputted.  useful troubleshooting. quiet TRUE, output produced using verbose = TRUE. setup_strategy \"parallel\" (default), workers set concurrently, one .  \"sequential\", set sequentially. action internal argument.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"object class c(\"RichSOCKcluster\", \"SOCKcluster\", \"cluster\")consisting list \"SOCKnode\" \"SOCK0node\" workers (also inherit RichSOCKnode). makeNodePSOCK() returns \"SOCKnode\" \"SOCK0node\" object representing established connection worker.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"definition-of-localhost","dir":"Reference","previous_headings":"","what":"Definition of localhost","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"hostname considered localhost equals: \"localhost\", \"127.0.0.1\", Sys.info()[[\"nodename\"]]. also considered localhost appears line value Sys.info()[[\"nodename\"]] file /etc/hosts.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"default-ssh-client-and-options-arguments-rshcmd-and-rshopts-","dir":"Reference","previous_headings":"","what":"Default SSH client and options (arguments rshcmd and rshopts)","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"Arguments rshcmd rshopts used connecting external host. default method connecting external host via SSH system executable given argument rshcmd.  default given option parallelly.makeNodePSOCK.rshcmd.  set, default use ssh Unix-like systems, including macOS well Windows 10.  older MS Windows versions, built-ssh client, default use () plink PuTTY project, (ii) ssh client distributed RStudio. PuTTY puts Windows' system PATH installed, meaning function find PuTTY automatically installed.  , manually set specify PuTTY SSH client, specify absolute pathname plink.exe first element option -ssh second rshcmd = c(\"C:/Path/PuTTY/plink.exe\", \"-ssh\"). elements rshcmd individually \"shell\" quoted element rshcmd[1] must system PATH. Furthermore, running R RStudio Windows, ssh client distributed RStudio also considered. client, MinGW MSYS, searched folder given RSTUDIO_MSYS_SSH environment variable - variable () set running RStudio. use SSH client outside RStudio, set RSTUDIO_MSYS_SSH accordingly. can override default set SSH clients searched specifying argument rshcmd via option parallelly.makeNodePSOCK.rshcmd using format <...>, e.g. rshcmd = c(\"<rstudio-ssh>\", \"<putty-plink>\", \"<ssh>\").  See examples. SSH-client found, informative error message produced. Additional SSH options may specified via argument rshopts, defaults option parallelly.makeNodePSOCK.rshopts. instance, private SSH key can provided rshopts = c(\"-\", \"~/.ssh/my_private_key\").  PuTTY users specify PuTTY PPK file, e.g. rshopts = c(\"-\", \"C:/Users/joe/.ssh/my_keys.ppk\"). Contrary rshcmd, elements rshopts quoted.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"accessing-external-machines-that-prompts-for-a-password","dir":"Reference","previous_headings":"","what":"Accessing external machines that prompts for a password","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"IMPORTANT: one exception, possible functions log launch R workers external machines requires password entered manually authentication. known exception PuTTY client Windows one can pass password via command-line option -pw, e.g. rshopts = c(\"-pw\", \"MySecretPassword\"). Note, depending whether run R terminal via GUI, might even see password prompt.  also likely enter password, connection set via background system call. poor man's workaround setup requires password manually log external machines launch R workers hand. approach, use manual = TRUE follow instructions include cut'n'pasteable commands launch worker external machine. However, much convenient less tedious method set key-based SSH authentication local machine external machine(s), explain .","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"accessing-external-machines-via-key-based-ssh-authentication","dir":"Reference","previous_headings":"","what":"Accessing external machines via key-based SSH authentication","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"best approach automatically launch R workers external machines SSH set key-based SSH authentication.  allow log external machine without enter password. Key-based SSH authentication taken care SSH client R. configure , see manuals SSH client search web \"ssh key authentication\".","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"reverse-ssh-tunneling","dir":"Reference","previous_headings":"","what":"Reverse SSH tunneling","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"default use reverse SSH tunneling (revtunnel = TRUE) workers running machines.  avoids complication otherwise configure port forwarding firewalls, often requires static IP address well privileges edit firewall outgoing router, something users . also advantage know internal / public IP address / hostname master. Yet another advantage need DNS lookup worker machines master, may configured disabled systems, e.g. compute clusters.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"argument-rscript","dir":"Reference","previous_headings":"","what":"Argument rscript","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"homogeneous FALSE, rscript defaults \"Rscript\", .e. assumed Rscript executable available PATH worker. homogeneous TRUE, rscript defaults file.path(R.home(\"bin\"), \"Rscript\"), .e. basically assumed worker caller share file system R installation. specified, argument rscript character vector one elements.  asterisk (\"*\") resolved default homogeneous-dependent Rscript path. elements automatically shell quoted using base::shQuote(), except format <ENVVAR>=<VALUE>, , ones matching regular expression '^[[:alpha:]_][[:alnum:]_]*=.*'. Another exception rscript inherits 'AsIs'.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"default-value-of-argument-homogeneous","dir":"Reference","previous_headings":"","what":"Default value of argument homogeneous","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"default value homogeneous TRUE either following fulfilled: worker localhost revtunnel FALSE master localhost worker neither IP number fully qualified domain name (FQDN).  hostname considered FQDN contains one periods cases, homogeneous defaults FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"connection-time-out","dir":"Reference","previous_headings":"","what":"Connection time out","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"Argument connectTimeout work properly Unix macOS due limitation R .  details , please see R-devel thread 'BUG?: Linux setTimeLimit() fails propagate timeout error occurs (works Windows)' 2016-10-26 (https://stat.ethz.ch/pipermail/r-devel/2016-October/073309.html). used, timeout eventually trigger error, happen socket connection timeout timeout happens.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"communication-time-out","dir":"Reference","previous_headings":"","what":"Communication time out","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"communication master worker within timeout limit, corresponding socket connection closed automatically.  eventually result error code trying access connection.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"failing-to-set-up-local-workers","dir":"Reference","previous_headings":"","what":"Failing to set up local workers","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"setting cluster localhost workers, , workers running machine master R process, occasionally connection worker (\"cluster node\") may fail set . occurs, informative error message troubleshooting suggestions produced. common reason localhost failures due port clashes.  Retrying often resolve problem.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"failing-to-set-up-remote-workers","dir":"Reference","previous_headings":"","what":"Failing to set up remote workers","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"cluster remote workers runs R processes external machines. external R processes launched , typically, SSH remote machine.  work, remote machines needs R installed, preferably version main machine.  work, required one can SSH remote machines.  Ideally, SSH connections use authentication based public-private SSH keys set remote workers can fully automated (see ).  makeClusterPSOCK() fails set one remote R workers, informative error message produced. reasons failing set remote workers.  happens, start asserting can SSH remote machine launch Rscript calling something like: confirmed work, confirm can achieve single command-line call; latter assert proper startup configuration also non-interactive shell sessions remote machine. Another reason failing setup remote workers running R version compatible version main R session running.  instance, run R (>= 3.6.0) locally workers run R (< 3.5.0), get: Error unserialize(node$con) : error reading connection. R (>= 3.6.0) uses serialization format version 3 default whereas R (< 3.5.0) supports version 2.  can see version R workers adding rscript_args = c(\"-e\", shQuote(\"getRversion()\")) calling makeClusterPSOCK().","code":"{local}$ ssh -l alice remote.server.org {remote}$ Rscript --version R scripting front-end version 3.6.1 (2019-07-05) {remote}$ logout {local}$ {local}$ ssh -l alice remote.server.org Rscript --version R scripting front-end version 3.6.1 (2019-07-05) {local}$"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"","code":"## NOTE: Drop 'dryrun = TRUE' below in order to actually connect.  Add ## 'verbose = TRUE' if you run into problems and need to troubleshoot.  ## EXAMPLE: Two workers on the local machine workers <- c(\"localhost\", \"localhost\") cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)  ## EXAMPLE: Three remote workers ## Setup of three R workers on two remote machines are set up workers <- c(\"n1.remote.org\", \"n2.remote.org\", \"n1.remote.org\") cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)  ## EXAMPLE: Local and remote workers ## Same setup when the two machines are on the local network and ## have identical software setups cl <- makeClusterPSOCK(   workers,   revtunnel = FALSE, homogeneous = TRUE,   dryrun = TRUE, quiet = TRUE )  ## EXAMPLE: Three remote workers 'n1', 'n2', and 'n3' that can only be ## accessed via jumphost 'login.remote.org' workers <- c(\"n1\", \"n2\", \"n1\") cl <- makeClusterPSOCK(   workers,   rshopts = c(\"-J\", \"login.remote.org\"),   homogeneous = FALSE,   dryrun = TRUE, quiet = TRUE )  ## EXAMPLE: Remote workers with specific setup ## Setup of remote worker with more detailed control on ## authentication and reverse SSH tunnelling cl <- makeClusterPSOCK(   \"remote.server.org\", user = \"johnny\",   ## Manual configuration of reverse SSH tunnelling   revtunnel = FALSE,   rshopts = c(\"-v\", \"-R 11000:gateway:11942\"),   master = \"gateway\", port = 11942,   ## Run Rscript nicely and skip any startup scripts   rscript = c(\"nice\", \"/path/to/Rscript\"),   dryrun = TRUE, quiet = TRUE )  ## EXAMPLE: Two workers running in Docker on the local machine ## Setup of 2 Docker workers running rocker/r-parallel cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Docker container   rscript = c(     \"docker\", \"run\", \"--net=host\", \"rocker/r-parallel\",     \"Rscript\"   ),   ## IMPORTANT: Because Docker runs inside a virtual machine (VM) on macOS   ## and Windows (not Linux), when the R worker tries to connect back to   ## the default 'localhost' it will fail, because the main R session is   ## not running in the VM, but outside on the host.  To reach the host on   ## macOS and Windows, make sure to use master = \"host.docker.internal\"   # master = \"host.docker.internal\",  # <= macOS & Windows   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Two workers running in Singularity on the local machine ## Setup of 2 Singularity workers running rocker/r-parallel cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Linux container   rscript = c(     \"singularity\", \"exec\", \"docker://rocker/r-parallel\",     \"Rscript\"   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: One worker running in udocker on the local machine ## Setup of a single udocker.py worker running rocker/r-parallel cl <- makeClusterPSOCK(   \"localhost\",   ## Launch Rscript inside Docker container (using udocker)   rscript = c(     \"udocker.py\", \"run\", \"rocker/r-parallel\",     \"Rscript\"   ),    ## Manually launch parallel workers   ## (need double shQuote():s because udocker.py drops one level)   rscript_args = c(     \"-e\", shQuote(shQuote(\"parallel:::.workRSOCK()\"))   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: One worker running in Wine for Linux on the local machine ## To install R for MS Windows in Wine, do something like: ## wget https://cran.r-project.org/bin/windows/base/R-4.1.2-win.exe ## wine R-4.1.2-win.exe /SILENT ## winecfg  # In GUI, set 'Windows version' to 'Windows 10' ## Verify it works: ## wine \"C:/Program Files/R/R-4.1.2/bin/x64/Rscript.exe\" --version cl <- makeClusterPSOCK(1L,   rscript = c(     ## Silence Wine warnings     \"WINEDEBUG=fixme-all\",     ## Don't pass LC_*** environments from Linux to Wine     sprintf(\"%s=\", grep(\"LC_\", names(Sys.getenv()), value = TRUE)),     \"wine\",     \"C:/Program Files/R/R-4.1.2/bin/x64/Rscript.exe\"   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Launch 124 workers on MS Windows 10, where half are ## running on CPU Group #0 and half on CPU Group #1.   ## (https://lovickconsulting.com/2021/11/18/ ##  running-r-clusters-on-an-amd-threadripper-3990x-in-windows-10-2/) ncores <- 124 cpu_groups <- c(0, 1) cl <- lapply(cpu_groups, FUN = function(cpu_group) {     parallelly::makeClusterPSOCK(ncores %/% length(cpu_groups),       rscript = I(c(         Sys.getenv(\"COMSPEC\"), \"/c\", \"start\", \"/B\",         \"/NODE\", cpu_group, \"/AFFINITY\", \"0xFFFFFFFFFFFFFFFE\",         \"*\"       )),       dryrun = TRUE, quiet = TRUE     ) }) ## merge the two 62-node clusters into one with 124 nodes cl <- do.call(c, cl) #> Warning: The combined cluster contains 61 duplicated nodes   ## EXAMPLE: Remote worker running on AWS ## Launching worker on Amazon AWS EC2 running one of the ## Amazon Machine Images (AMI) provided by RStudio ## (https://www.louisaslett.com/RStudio_AMI/) public_ip <- \"1.2.3.4\" ssh_private_key_file <- \"~/.ssh/my-private-aws-key.pem\" cl <- makeClusterPSOCK(   ## Public IP number of EC2 instance   public_ip,   ## User name (always 'ubuntu')   user = \"ubuntu\",   ## Use private SSH key registered with AWS   rshopts = c(     \"-o\", \"StrictHostKeyChecking=no\",     \"-o\", \"IdentitiesOnly=yes\",     \"-i\", ssh_private_key_file   ),   ## Set up .libPaths() for the 'ubuntu' user   ## and then install the future package   rscript_startup = quote(local({     p <- Sys.getenv(\"R_LIBS_USER\")     dir.create(p, recursive = TRUE, showWarnings = FALSE)     .libPaths(p)     install.packages(\"future\")   })),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Remote worker running on GCE ## Launching worker on Google Cloud Engine (GCE) running a ## container based VM (with a #cloud-config specification) public_ip <- \"1.2.3.4\" user <- \"johnny\" ssh_private_key_file <- \"~/.ssh/google_compute_engine\" cl <- makeClusterPSOCK(   ## Public IP number of GCE instance   public_ip,   ## User name (== SSH key label (sic!))   user = user,   ## Use private SSH key registered with GCE   rshopts = c(     \"-o\", \"StrictHostKeyChecking=no\",     \"-o\", \"IdentitiesOnly=yes\",     \"-i\", ssh_private_key_file   ),   ## Launch Rscript inside Docker container   rscript = c(     \"docker\", \"run\", \"--net=host\", \"rocker/r-parallel\",     \"Rscript\"   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Remote worker running on Linux from Windows machine ## Connect to remote Unix machine 'remote.server.org' on port 2200 ## as user 'bob' from a Windows machine with PuTTY installed. ## Using the explicit special rshcmd = \"<putty-plink>\", will force ## makeClusterPSOCK() to search for and use the PuTTY plink software, ## preventing it from using other SSH clients on the system search PATH. cl <- makeClusterPSOCK(   \"remote.server.org\", user = \"bob\",   rshcmd = \"<putty-plink>\",   rshopts = c(\"-P\", 2200, \"-i\", \"C:/Users/bobby/.ssh/putty.ppk\"),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Remote worker running on Linux from RStudio on Windows ## Connect to remote Unix machine 'remote.server.org' on port 2200 ## as user 'bob' from a Windows machine via RStudio's SSH client. ## Using the explicit special rshcmd = \"<rstudio-ssh>\", will force ## makeClusterPSOCK() to use the SSH client that comes with RStudio, ## preventing it from using other SSH clients on the system search PATH. cl <- makeClusterPSOCK(   \"remote.server.org\", user = \"bob\", rshcmd = \"<rstudio-ssh>\",   dryrun = TRUE, quiet = TRUE ) #> Warning: Failed to locate a default SSH client (checked: ‘rstudio-ssh’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’."},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Options Used by the 'parallelly' Package — parallelly.options","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables used parallelly package packages enhancing .WARNING: Note names default values options may change future versions package.  Please use care notice.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"backward-compatibility-with-the-future-package","dir":"Reference","previous_headings":"","what":"Backward compatibility with the future package","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"functions parallelly package originates future package.  widely used within future ecosystem, need keep backward compatible quite long time, order existing packages R scripts time adjust. also goes R options environment variables used configure functions. options environment variables used prefixes parallelly. R_PARALLELLY_, respectively.  backward compatibility future package, settings can also controlled options environment variables prefixes future. R_FUTURE_ notice, e.g. setting option future.availableCores.fallback=1 setting option parallelly.availableCores.fallback=1, setting environment variable R_FUTURE_AVAILABLECORES_FALLBACK=1 setting R_PARALLELLY_AVAILABLECORES_FALLBACK=1.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"configuring-number-of-parallel-workers","dir":"Reference","previous_headings":"","what":"Configuring number of parallel workers","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables control default results availableCores() availableWorkers(). parallelly.availableCores.logical: (logical) default value argument logical used availableCores(), availableWorkers(), availableCores() querying parallel::detectCores(logical = logical).  default TRUE just like parallel::detectCores(). parallelly.availableCores.methods: (character vector) Default lookup methods availableCores(). (Default: c(\"system\", \"nproc\", \"mc.cores\", \"_R_CHECK_LIMIT_CORES_\", \"PBS\", \"SGE\", \"Slurm\", \"LSF\", \"fallback\", \"custom\")) parallelly.availableCores.custom: (function) set function, function called (without arguments) availableCores() value, coerced integer, interpreted number cores. parallelly.availableCores.fallback: (integer) Number cores use core-specifying settings detected \"system\" \"nproc\".  options makes possible set default number cores returned availableCores() / availableWorkers() yet allow users schedulers override .  multi-tenant environment, HPC clusters, useful set environment variable R_PARALLELLY_AVAILABLECORES_FALLBACK 1, set option package loaded. parallelly.availableCores.system: (integer) Number \"system\" cores used instead reported availableCores(= \"system\"). option allows effectively override parallel::detectCores() reports system . parallelly.availableCores.omit: (integer) Number cores set aside, .e. include. parallelly.availableWorkers.methods: (character vector) Default lookup methods availableWorkers(). (Default: c(\"mc.cores\", \"_R_CHECK_LIMIT_CORES_\", \"PBS\", \"SGE\", \"Slurm\", \"LSF\", \"custom\", \"system\", \"fallback\")) parallelly.availableWorkers.custom: (function) set function, function called (without arguments) availableWorkers() value, coerced character vector, interpreted hostnames available workers.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"configuring-forked-parallel-processing","dir":"Reference","previous_headings":"","what":"Configuring forked parallel processing","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables control default result supportsMulticore(). parallelly.fork.enable: (logical) Enable disable forked processing.  FALSE, multicore futures becomes sequential futures.  NA, set (default), set best-practices rules decide whether supported . parallelly.supportsMulticore.unstable: (character) Controls whether warning produced whenever multicore processing automatically disabled environment R runs considered unstable forked processing, e.g. RStudio environment.  \"warn\" (default), informative warning produces first time 'multicore' 'multiprocess' futures used.  \"quiet\", warning produced.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"configuring-setup-of-parallel-psock-clusters","dir":"Reference","previous_headings":"","what":"Configuring setup of parallel PSOCK clusters","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables control default results makeClusterPSOCK() helper function makeNodePSOCK() creates individual cluster nodes. parallelly.makeNodePSOCK.setup_strategy: (character) \"parallel\" (default), PSOCK cluster nodes set concurrently.  \"sequential\", set sequentially. parallelly.makeNodePSOCK.validate: (logical) TRUE (default), nodes created, validated work inquiring session information, saved attribute session_info node. parallelly.makeNodePSOCK.connectTimeout: (numeric) maximum time (seconds) allowed socket connection master worker established (defaults 2*60 seconds = 2 minutes). parallelly.makeNodePSOCK.timeout: (numeric) maximum time (seconds) allowed pass without master worker communicate (defaults 302460*60 seconds = 30 days). parallelly.makeNodePSOCK.useXDR: (logical) FALSE (default), communication master workers, binary, use small-endian (faster), otherwise big-endian (\"XDR\"; slower). parallelly.makeNodePSOCK.socketOptions: (character string) set another value \"NULL\", option socketOptions set value workers startup. See base::socketConnection() details. (defaults \"-delay\") parallelly.makeNodePSOCK.rshcmd: (character vector) command run master launch process another host. parallelly.makeNodePSOCK.rshopts: (character vector) Addition command-line options appended rshcmd.  arguments applied connecting non-localhost machines. parallelly.makeNodePSOCK.tries: (integer) maximum number attempts done launch node.  used setting cluster nodes using sequential strategy. parallelly.makeNodePSOCK.tries.delay: (numeric) number seconds wait trying launch cluster node failed launch previously.  used setting cluster nodes using sequential strategy.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"options-for-debugging","dir":"Reference","previous_headings":"","what":"Options for debugging","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"parallelly.debug: (logical) TRUE, extensive debug messages generated. (Default: FALSE)","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"environment-variables-that-set-r-options","dir":"Reference","previous_headings":"","what":"Environment variables that set R options","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R parallelly.* options can set corresponding environment variables R_PARALLELLY_* parallelly package loaded. example, R_PARALLELLY_MAKENODEPSOCK_SETUP_STRATEGY = \"sequential\", option parallelly.makeNodePSOCK.setup_strategy set \"sequential\" (character). Similarly, R_PARALLELLY_AVAILABLECORES_FALLBACK = \"1\", option parallelly.availableCores.fallback set 1 (integer).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"","code":"# Set an R option: options(parallelly.availableCores.fallback = 1L)"},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether a process PID exists or not — pid_exists","title":"Check whether a process PID exists or not — pid_exists","text":"Check whether process PID exists ","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether a process PID exists or not — pid_exists","text":"","code":"pid_exists(pid, debug = getOption2(\"parallelly.debug\", FALSE))"},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether a process PID exists or not — pid_exists","text":"pid positive integer.","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether a process PID exists or not — pid_exists","text":"Returns TRUE process given PID exists, FALSE process given PID exists, NA possible check PIDs current system.","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether a process PID exists or not — pid_exists","text":"single go-function R testing whether PID exists .  Instead, function tries identify working one among multiple possible alternatives.  method considered working PID current process successfully identified existing pid_exists(Sys.getpid()) TRUE.  working approach found, pid_exists() always return NA regardless PID tested. Unix, including macOS, alternatives tools::pskill(pid, signal = 0L) system2(\"ps\", args = pid) used. Windows, various alternatives system2(\"tasklist\", ...) used.","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check whether a process PID exists or not — pid_exists","text":"Open Group Base Specifications Issue 7, 2018 edition, IEEE Std 1003.1-2017 (Revision IEEE Std 1003.1-2008) https://pubs.opengroup.org/onlinepubs/9699919799/functions/kill.html Microsoft, tasklist, 2018-08-30, https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/tasklist R-devel thread 'Detecting whether process exists PID?', 2018-08-30. https://stat.ethz.ch/pipermail/r-devel/2018-August/076702.html","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":null,"dir":"Reference","previous_headings":"","what":"Check If Forked Processing (","title":"Check If Forked Processing (","text":"Certain parallelization methods R rely forked processing, e.g. parallel::mclapply(), parallel::makeCluster(n, type = \"FORK\"), doMC::registerDoMC(), future::plan(\"multicore\"). Process forking done operating system support R restricted Unix-like operating systems Linux, Solaris, macOS.  R running Microsoft Windows support forked processing. R, forked processing often referred \"multicore\" processing, stems 'mc' mclapply() family functions, originally package named multicore later incorporated parallel package. function checks whether forked (aka \"multicore\") processing supported current R session.","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check If Forked Processing (","text":"","code":"supportsMulticore(...)"},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check If Forked Processing (","text":"... Internal usage .","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check If Forked Processing (","text":"TRUE forked processing supported disabled, otherwise FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"support-for-process-forking","dir":"Reference","previous_headings":"","what":"Support for process forking","title":"Check If Forked Processing (","text":"R supports forked processing Unix-like operating system Linux macOS, Microsoft Windows operating system. R environments considered unstable perform parallel processing based forking. example case using RStudio, cf. RStudio Inc. recommends using forked processing running R within RStudio software. function detects running environment returns FALSE, despite underlying operating system supports forked processing. warning also produced informing user first time time function called R session. warning can disabled setting R option parallelly.supportsMulticore.unstable, environment variable R_PARALLELLY_SUPPORTSMULTICORE_UNSTABLE \"quiet\".","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"enable-or-disable-forked-processing","dir":"Reference","previous_headings":"","what":"Enable or disable forked processing","title":"Check If Forked Processing (","text":"possible disable forked processing futures setting R option parallelly.fork.enable FALSE.  Alternatively, one can set environment variable R_PARALLELLY_FORK_ENABLE false. Analogously, possible override disabled forking setting one TRUE.","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check If Forked Processing (","text":"","code":"## Check whether or not forked processing is supported supportsMulticore() #> [1] TRUE"},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-30-0-9002","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.30.0-9002","text":"Changed default argument `default` freePort() `“random”`, used `“first”`. main reason make sure default behavior return random port also R (< 4.0.0) get whether port available.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-30-0-9002","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.30.0-9002","text":"availableCores() return ‘fallback’ value ‘system’ ‘nproc’ information available. However, case, want return ‘nproc’ ‘nproc’ != ‘system’, strong indication number CPU cores limited control groups (cgroups) Linux. ‘nproc’ == ‘system’, tell whether cgroups enabled , means fall back ‘fallback’ value evidence another number cores available current R process.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1300","dir":"Changelog","previous_headings":"","what":"parallelly 1.30.0","title":"parallelly 1.30.0","text":"CRAN release: 2021-12-17","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-30-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.30.0","text":"makeNodePSOCK(), therefore also makeClusterPSOCK(), gained argument ‘rscript_sh’, controls Rscript arguments shell quoted. default make best guess type shell used cluster node launched. launched locally, whatever platform current R session running, .e. either POSIX shell (“sh”) MS Windows (“cmd”). remotely, assumption POSIX shell (“sh”) used. makeNodePSOCK(), therefore also makeClusterPSOCK(), gained argument ‘default_packages’, controls default set R packages attached cluster node startup. Moreover, argument ‘rscript’ specifies ‘Rscript’ executable, argument ‘default_packages’ used populate Rscript command-line option ‘–default-packages=…’. ‘rscript’ specifies something else, e.g. ‘R’ ‘Rterm’ executable, environment variable ‘R_DEFAULT_PACKAGES=…’ set accordingly launching cluster node. Argument ‘rscript_args’ makeClusterPSOCK() now supports “*” values. used, corresponding element replaced internally added Rscript command-line options. specified, options appended end.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-30-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.30.0","text":"makeClusterPSOCK() support backslashes (‘') ’rscript_libs’, backslashes may originate , example, Windows network drives. result worker silently ignore ‘rscript_libs’ components backslashes. package detects ‘R CMD check’ runs adjust default settings via environment variables order play nicer machine checks running. environment variables case ignored since parallelly 1.26.0.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1290","dir":"Changelog","previous_headings":"","what":"parallelly 1.29.0","title":"parallelly 1.29.0","text":"CRAN release: 2021-11-21","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-29-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.29.0","text":"makeClusterPSOCK() launches parallel workers option ‘socketOptions’ set “-delay” default. decreases communication latency workers main R session, significantly Unix. option requires R (>= 4.1.0) effect early versions R.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-29-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.29.0","text":"Added argument ‘socketOptions’ makeClusterPSOCK(), sets corresponding R option cluster node launched. Argument ‘rscript_envs’ makeClusterPSOCK() can also used unset environment variables cluster nodes. named element value ‘NA_character_’ unset. Argument ‘rscript’ makeClusterPSOCK() now supports “*” values. used, corresponding element replaced “Rscript”, ‘homogenous = TRUE’, absolute path current “Rscript”.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-29-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"parallelly 1.29.0","text":"Add makeClusterPSOCK() example launch workers distributed across multiple CPU Groups MS Windows 10.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-29-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.29.0","text":"isForkedChild() return TRUE forked child process, , already called parent R process. Using argument ‘rscript_startup’ cause makeClusterPSOCK() fail R-devel (>= r80666).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1281","dir":"Changelog","previous_headings":"","what":"parallelly 1.28.1","title":"parallelly 1.28.1","text":"CRAN release: 2021-09-09","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"cran-policies-1-28-1","dir":"Changelog","previous_headings":"","what":"Cran Policies","title":"parallelly 1.28.1","text":"example(“isNodeAlive”) now uses  avoid long (> 10 s) elapsed run times MS Windows.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-28-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.28.0","text":"Add isNodeAlive() check whether cluster cluster nodes alive . Add isForkedChild() check whether current R process forked child process.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-28-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.28.0","text":"Environment variable ‘R_PARALLELLY_SUPPORTSMULTICORE_UNSTABLE’ incorrectly parsed logical instead character string. variables set , say, “quiet”, cause error package loaded. makeClusterPSOCK() failed fall back setup_strategy = “sequential”, supported current R version.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1270","dir":"Changelog","previous_headings":"","what":"parallelly 1.27.0","title":"parallelly 1.27.0","text":"CRAN release: 2021-07-19","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-27-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.27.0","text":"availableCores() availableWorkers() now respects environment variable ‘BIOCPARALLEL_WORKER_NUMBER’ introduced BiocParallel (>= 1.27.2). also respect ‘BBS_HOME’ set Bioconductor check servers limit number parallel workers checking Bioconductor packages.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"workaround-1-27-0","dir":"Changelog","previous_headings":"","what":"Workaround","title":"parallelly 1.27.0","text":"makeClusterPSOCK() parallel::makeCluster() failed error “Cluster setup failed. <n> <n> workers failed connect.” using new default ‘setup_strategy = “parallel”’ ‘tcltk’ package loaded running R (>= 4.0.0 && <= 4.1.0) macOS. Now ‘parallelly’ forces setup_strategy = “sequential” ‘tcltk’ package loaded R versions.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-27-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.27.0","text":"makeClusterPSOCK(…, setup_strategy = “parallel”) forget close socket connection used set workers. socket connection closed garbage collector eventually warning. parallelly::makeClusterPSOCK() fail “Error freePort(port) : Unknown value argument ‘port’: ‘auto’” environment variable ‘R_PARALLEL_PORT’ set port number. parallelly::availableCores() produce ‘Error (grepl(“^ [1-9]$”, res)) return(.integer(res)) : argument length zero’ Linux systems without ‘nproc’ installed.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1261","dir":"Changelog","previous_headings":"","what":"parallelly 1.26.1","title":"parallelly 1.26.1","text":"CRAN release: 2021-06-30","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-26-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.26.1","text":"print() RichSOCKcluster mentions cluster registered automatically stopped garbage collector.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"workaround-1-26-1","dir":"Changelog","previous_headings":"","what":"Workaround","title":"parallelly 1.26.1","text":"Depending R version used, RStudio Console support new ‘setup_strategy = “parallel”’ using makeClusterPSOCK() parallel::makeCluster(). symptom , long wait, result “Error makeClusterPSOCK(workers, …) : Cluster setup failed. <n> <n> workers failed connect.” due bug R, fixed R (>= 4.1.1) also recent R 4.1.0 Patched. R (>= 4.0.0) R (<= 4.1.0), release works around problem forcing ‘setup_strategy = “sequential” ’parallelly’ ‘parallel’ running RStudio Console. wish override behavior, can always set option ‘parallelly.makeNodePSOCK.setup_strategy’ “parallel”, e.g. ~/.Rprofile file. Alternatively, can set environment variable ‘R_PARALLELLY_MAKENODEPSOCK_SETUP_STRATEGY=parallel’, e.g. ~/.Renviron file.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-26-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.26.1","text":"systems ‘nproc’ installed, availableCores() limited environment variables ‘OMP_NUM_THREADS’ ‘OMP_THREAD_LIMIT’, set. example, conservative systems set ‘OMP_NUM_THREADS=1’ default, availableCores() pick via ‘nproc’ return 1. intended behavior. Now environment variables temporarily unset querying ‘nproc’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1260","dir":"Changelog","previous_headings":"","what":"parallelly 1.26.0","title":"parallelly 1.26.0","text":"CRAN release: 2021-06-09","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-26-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.26.0","text":"R_PARALLELLY_* (R_FUTURE_*) environment variables now read ‘parallelly’ package loaded, set corresponding parallelly.* option. Previously, environment variables queried different functions fallback option set. parsing package loaded, decrease overhead functions, clarifies options can changed runtime whereas environment variables set startup.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-26-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.26.0","text":"makeClusterPSOCK() now support setting cluster nodes parallel similarly parallel::makePSOCKcluster() . significantly reduces setup turnaround time. supported R (>= 4.0.0). revert sequential setup strategy, set R option ‘parallelly.makeNodePSOCK.setup_strategy’ “sequential”. Add freePort() get random TCP port can opened.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-26-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"parallelly 1.26.0","text":"Documenting R options environment variables used package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-26-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.26.0","text":"R option ‘parallelly.availableCores.fallback’ environment variable ‘R_PARALLELLY_AVAILABLECORES_FALLBACK’ ignored since parallelly 1.22.0, support ‘nproc’ added availableCores().","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1250","dir":"Changelog","previous_headings":"","what":"parallelly 1.25.0","title":"parallelly 1.25.0","text":"CRAN release: 2021-04-30","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-25-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.25.0","text":"default SSH client MS Windows 10 now built ‘ssh’ client. means regardless whether Linux, macOS, Windows 10, setting parallel workers external machines SSH finally works box without install PuTTY SSH clients. possible workaround found Windows 10 bug preventing us using reverse tunneling SSH. turns bug reveals using hostname ‘localhost’ ‘127.0.0.1’, use latter.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-25-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.25.0","text":"availableCores() gained argument ‘omit’ make easier put aside zero cores used parallel processing. example, system four cores, availableCores(omit = 1) returns 3. Importantly, since availableCores() guaranteed always return positive integer, availableCores(omit = 4) == 1, even systems four fewer cores. Using availableCores() - 4 systems return non-positive value, give error downstream.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-25-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.25.0","text":"makeClusterPSOCK(), actually makeNodePSOCK(), accept types environment variable names using ‘rscript_envs’, e.g. give error tried pass ‘_R_CLASS_MATRIX_ARRAY_’. makeClusterPSOCK() “length > 1 coercion logical” bug affect especially MS Windows 10 users.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1240","dir":"Changelog","previous_headings":"","what":"parallelly 1.24.0","title":"parallelly 1.24.0","text":"CRAN release: 2021-03-14","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-24-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.24.0","text":"default SSH client MS Windows now, order availability: () ‘plink’ PuTTY software, (ii) ‘ssh’ RStudio distribution, (iii) ‘ssh’ Windows 10. Previously, latter considered first still bug preventing us using reverse tunneling.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-24-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.24.0","text":"makeClusterPSOCK(), actually makeNodePSOCK(), gained argument ‘quiet’, can used silence output produced ‘manual = TRUE’. c() ‘cluster’ objects now warns duplicated cluster nodes. Add isForkedNode() test cluster node runs forked process. Add isLocalhostNode() test cluster node runs current machine. Now availableCores() availableWorkers() avoid recursive calls custom function given options ‘parallelly.availableCores.custom’ ‘parallelly.availableWorkers.custom’, respectively. availableWorkers() now recognizes Slurm environment variable ‘SLURM_JOB_NODELIST’, e.g. “dev1,n[3-4,095-120]”. use ‘scontrol show hostnames “$SLURM_JOB_NODELIST”’ expand , supported current machine, otherwise attempt parse expand nodelist specification using R. either environment variable ‘SLURM_JOB_CPUS_PER_NODE’ ‘SLURM_TASKS_PER_NODE’ set, node nodelist represented number times. addition, environment variable ‘SLURM_CPUS_PER_TASK’ (always scalar), also respected.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-24-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"parallelly 1.24.0","text":"code now using ‘parallelly.’ prefix options ‘R_PARALLELLY_’ prefix environment variables. Settings use corresponding ‘future.’ ‘R_FUTURE_’ prefixes still recognized.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-24-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.24.0","text":"availableCores() respect environment variable ‘SLURM_TASKS_PER_NODE’ job allocated one node. argument ‘quiet’ introduced future 1.19.1 mistakenly dropped parallelly 1.20.0 released, therefore also future (>= 1.20.0).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1230","dir":"Changelog","previous_headings":"","what":"parallelly 1.23.0","title":"parallelly 1.23.0","text":"CRAN release: 2021-01-04","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-23-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.23.0","text":"availableCores(), availableWorkers(), freeCores() gained argument ‘logical’, passed parallel::detectCores() -. default TRUE can changed setting R option ‘parallelly.availableCores.logical’. option can turn set via environment variable ‘R_PARALLELLY_AVAILABLECORES_LOGICAL’ applied () package loaded. Now makeClusterPSOCK() asserts enough free connections available attempting create parallel workers. many workers requested, informative error message produced. Add availableConnections() freeConnections() infer maximum number connections current R installation can open time many currently free used. limit typically 128 may different custom R installations built source.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1220","dir":"Changelog","previous_headings":"","what":"parallelly 1.22.0","title":"parallelly 1.22.0","text":"CRAN release: 2020-12-13","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-22-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.22.0","text":"Now availableCores() queries also Unix command ‘nproc’, available. make respect number CPU/cores limited ‘cgroups’ Linux containers. PSOCK cluster workers now set communicate using little endian (useXDR = FALSE) instead big endian (useXDR = TRUE). Since modern systems use little endian, ‘useXDR = FALSE’ speeds communication noticeably (10-15%) systems. default value argument can controlled R option ‘parallelly.makeNodePSOCK.useXDR’ corresponding environment variable ‘R_PARALLELLY_MAKENODEPSOCK_USEXDR’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"beta-features-1-22-0","dir":"Changelog","previous_headings":"","what":"Beta Features","title":"parallelly 1.22.0","text":"Add cpuLoad() querying “average” system load Unix-like systems. Add freeCores() estimating average number unused cores based average system load given cpuLoad().","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-22-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.22.0","text":"Except environment variables ‘R_FUTURE_AVAILABLECORES_FALLBACK’ ‘R_FUTURE_AVAILABLECORES_SYSTEM’, none ‘R_PARALLELLY_*’ ‘R_FUTURE_*’ ones recognized.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1210","dir":"Changelog","previous_headings":"","what":"parallelly 1.21.0","title":"parallelly 1.21.0","text":"CRAN release: 2020-10-27","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-21-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.21.0","text":"Removed find_rshcmd() never meant exported.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-21-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.21.0","text":"makeClusterPSOCK() gained argument ‘validate’ control whether nodes tested ’ve created. validation done querying node session information, saved attribute ‘session_info’ cluster node object. information also used error messages, available. validation done since version 1.5.0 now can disabled. default argument ‘validate’ can controlled via R options environment variable. Now makeNodePSOCK(…, rscript_envs = “UNKNOWN”) produces informative warning non-existing environment variables skipped.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-21-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.21.0","text":"makeClusterPSOCK() produce error ‘one node produced error: find function “getOptionOrEnvVar”’ ‘parallelly’ available node. makeClusterPSOCK() attempt loaded ‘parallelly’ worker. ’s available worker, result silent warning worker. Now ‘parallelly’ loaded. makeClusterPSOCK(…, tries = n) retry setup cluster node also errors unrelated node setup node connection errors. error message using invalid ‘rscript_envs’ argument makeClusterPSOCK() reported value ‘rscript_libs’ (sic!). makeNodePSOCK(…, rscript_envs = “UNKNOWN”) result error trying launch cluster node.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"deprecated-and-defunct-1-21-0","dir":"Changelog","previous_headings":"","what":"Deprecated and Defunct","title":"parallelly 1.21.0","text":"Removed find_rshcmd() never meant exported.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"parallelly-1200","dir":"Changelog","previous_headings":"","what":"parallelly 1.20.0","title":"parallelly 1.20.0","text":"CRAN release: 2020-10-20","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-20-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.20.0","text":"Add availableCores(), availableWorkers(), supportsMulticore(), .cluster(), autoStopCluster(), makeClusterMPI(), makeClusterPSOCK(), makeNodePSOCK() ‘future’ package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-20-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.20.0","text":"Add isConnectionValid() connectionId() adopted internal code ‘future’ package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-20-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.20.0","text":"Renamed environment variable ‘R_FUTURE_MAKENODEPSOCK_tries’ used makeClusterPSOCK() ‘R_FUTURE_MAKENODEPSOCK_TRIES’. connectionId() return -1L Solaris connections internal ‘nil’ pointers reported ‘0’ - ‘nil’ ‘0x0’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"history-1-20-0","dir":"Changelog","previous_headings":"","what":"History","title":"parallelly 1.20.0","text":"excerpt future’s NEWS entries related functions package.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-19-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"parallelly 1.19.0","text":"Now availableCores() better supports Slurm. Specifically, environment variable ‘SLURM_CPUS_PER_TASK’ set, requires option –slurm-cpus-per-task=n’ specified SLURM_JOB_NUM_NODES=1, falls back using ‘SLURM_CPUS_ON_NODE’, e.g. using ‘–ntasks=n’. Now availableCores() availableWorkers() supports LSF/OpenLava. Specifically, acknowledge environment variable ‘LSB_DJOB_NUMPROC’ ‘LSB_HOSTS’, respectively.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-19-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.19.0","text":"makeClusterPSOCK() now retry create cluster node ‘tries’ (default: 3) times giving . argument ‘port’ species one port (e.g. port = “random”) also attempt find valid random port ‘tries’ times giving . pre-validation random port supported R (>= 4.0.0) skipped otherwise. makeClusterPSOCK() skips shell quoting elements ‘rscript’ inherits ‘AsIs’. makeClusterPSOCK(), actually makeNodePSOCK(), gained argument ‘quiet’, can used silence output produced ‘manual = TRUE’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"performance-1-19-0","dir":"Changelog","previous_headings":"","what":"Performance","title":"parallelly 1.19.0","text":"Now plan(multisession), plan(cluster, workers = <number>), makeClusterPSOCK() use internally, sets localhost workers twice fast compared versions since future 1.12.0, brings back par bare-bone parallel::makeCluster(…, setup_strategy = “sequential”) setup. slowdown introduced future 1.12.0 (2019-03-07) protection leaving stray R processes behind failed worker startup implemented. protection now makes use memoization speedup.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-18-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.18.0","text":"print() RichSOCKcluster gives information name host also version R platform node (“worker”), e.g. “Socket cluster 3 nodes 2 nodes host ‘localhost’ (R version 4.0.0 (2020-04-24), platform x86_64-w64-mingw32), 1 node host ‘n3’ (R version 3.6.3 (2020-02-29), platform x86_64-pc-linux-gnu)”. now possible set environment variables workers launched makeClusterPSOCK() specify “<name>=<value>” part ‘rscript’ vector argument, e.g. rscript=c(“ABC=123”, “DEF=‘hello world’”, “Rscript”). works elements ‘rscript’ match regular expression ‘^ [[:alpha:]_][[:alnum:]_]*=.*’ longer shell quoted. makeClusterPSOCK() now returns cluster addition inheriting ’ SOCKcluster’ also inherit ‘RichSOCKcluster’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-18-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.18.0","text":"Made makeClusterPSOCK() makeNodePSOCK() agile name change parallel:::.slaveRSOCK() parallel:::.workRSOCK() R (>= 4.1.0). makeClusterPSOCK(…, rscript) try locate rscript[1] argument ‘homogeneous’ FALSE (inferred FALSE). makeClusterPSOCK(…, rscript_envs) result syntax error starting workers due non-ASCII quotation marks option ‘useFancyQuotes’ set FALSE.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-17-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.17.0","text":"makeClusterPSOCK() gained argument ‘rscript_envs’ setting environment variables workers startup, e.g. rscript_envs = c(FOO = “3.14”, “BAR”).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-17-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"parallelly 1.17.0","text":"CRAN servers _R_CHECK_LIMIT_CORES_ set. better emulate CRAN submission checks, future package , loaded, set environment variable ‘TRUE’ unset ‘R CMD check’ running. Note future::availableCores() respects _R_CHECK_LIMIT_CORES_ returns 2L (two cores) detected.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-15-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.15.1","text":"default range ports makeClusterPSOCK() draws random port (argument ‘port’ specified) can now controlled environment variable ‘R_FUTURE_RANDOM_PORTS’. default range still 11000:11999 ‘parallel’ package.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-15-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"parallelly 1.15.0","text":"Added ‘Troubleshooting’ section ?makeClusterPSOCK instructions troubleshoot setup local remote clusters fail.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-15-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.15.0","text":"makeClusterPSOCK() produce warnings like “open file ‘/tmp/alice/Rtmpi69yYF/future.parent=2622.a3e32bc6af7.pid’: file”, e.g. launching R workers running Docker containers. makeClusterMPI() work MPI clusters ‘comm’ ‘1’.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-13-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.13.0","text":"Now availableCores() also recognizes PBS environment variable ‘NCPUS’, PBSPro scheduler set ‘PBS_NUM_PPN’. , option ‘future.availableCores.custom’ set function, availableCores() call function interpret value number cores. Analogously, option ‘future.availableWorkers.custom’ can used specify hostnames set workers availableWorkers() sees. new options provide mechanism anyone customize availableCores() availableWorkers() case (yet) recognize, say, environment variables specific user’s compute environment HPC scheduler. makeClusterPSOCK() gained support argument ‘rscript_startup’ evaluating one R expressions background R worker prior worker event loop launching. provides convenient approach use, say, ‘rscript_args = c(“-e”, sQuote(code))’. makeClusterPSOCK() gained support argument ‘rscript_libs’ control R package library search path workers. example, _prepend_ folder ‘~/R-libs’ workers, use ‘rscript_libs = c(“~/R-libs”, “*”)’, “*” resolved current ‘.libPaths()’ workers.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-13-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.13.0","text":"makeClusterPSOCK() shell quote Rscript executable running pre-tests checking whether localhost Rscript processes can killed PIDs .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-12-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.12.0","text":"makeClusterPSOCK() fails create one many nodes, attempt stop nodes successfully created. lowers risk leaving R worker processes behind.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-12-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.12.0","text":"makeClusterPSOCK() future (>= 1.11.1) produced warnings argument ‘rscript’ length(rscript) > 1.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-11-1-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.11.1.1","text":"makeClusterPSOCK() fails connect worker, produces error detailed information happened. rare cases, another error produced generating information workers PID .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-11-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.11.1","text":"defaults several arguments makeClusterPSOCK() makeNodePSOCK() can now controlled via environment variables addition R options supported past. advantage using environment variables inherited child processes, also nested ones.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"software-quality-1-11-1","dir":"Changelog","previous_headings":"","what":"Software Quality","title":"parallelly 1.11.1","text":"TESTS: ‘future’ package loaded, checks whether ‘R CMD check’ running . , future-specific environment variables adjusted tests play nice testing environment. instance, sets socket connection timeout PSOCK cluster workers 120 seconds (instead default 30 days!). lower risk zombie worker processes cluttering test machine (e.g. CRAN servers) case worker process left behind despite main R processes terminated. Note adjustments applied automatically checks package depends , imports, ‘future’ package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-11-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.11.1","text":"Whenever makeClusterPSOCK() fail connect worker, instance due port clash, leave R worker process running - also main R process terminated. worker running machine, makeClusterPSOCK() now attempt kill stray R processes. Note parallel::makePSOCKcluster() still problem.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-11-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.11.0","text":"makeClusterPSOCK() produces informative error messages whenever setup R workers fails. Also, verbose messages now prefixed “[local output]” help distinguish output produced current R session produced background workers. now possible specify type SSH clients makeClusterPSOCK() automatically searches order, e.g. ‘rshcmd = c(“<rstudio-ssh>”, “<putty-plink>”)’. Now makeClusterPSOCK() preserves global RNG state (.Random.seed) also draws random port number. makeClusterPSOCK() gained argument ‘rshlogfile’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-11-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.11.0","text":"makeClusterPSOCK(…, rscript = “my_r”) cases fail find intended ‘my_r’ executable.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-10-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.10.0","text":"Add makeClusterMPI(n) creating MPI-based clusters similar kind parallel::makeCluster(n, type = “MPI”) also attempts workaround issues parallel::stopCluster() causes R stall. makeClusterPSOCK() makeClusterMPI() gained argument ‘autoStop’ controlling whether cluster automatically stopped garbage collected .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-9-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.9.0","text":"makeClusterPSOCK() produced warning environment variable ‘R_PARALLEL_PORT’ set ‘random’ (e.g. CRAN).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-8-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.8.1","text":"makeClusterPSOCK() now produces informative warning environment variable R_PARALLEL_PORT specifies non-numeric port.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-7-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.7.0","text":"Windows, makeClusterPSOCK(), therefore plan(multisession) plan(multiprocess), use SSH client distributed RStudio fallback neither ‘ssh’ ‘plink’ available system PATH.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-7-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.7.0","text":"makeClusterPSOCK(…, renice = 19) launch PSOCK worker via ‘nice +19’ resulting error “nice: ‘+19’: file directory”. bug inherited parallel::makePSOCKcluster(). Now using ‘nice –adjustment=19’ instead.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-5-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.5.0","text":"makeClusterPSOCK() now defaults use Windows PuTTY software’s SSH client ‘plink -ssh’, ‘ssh’ found. Argument ‘homogeneous’ makeNodePSOCK(), helper function makeClusterPSOCK(), default FALSE also hostname fully qualified domain name (FQDN), , “contains periods”. instance, c(‘node1’, ‘node2.server.org’) use homogeneous = TRUE first worker homogeneous = FALSE second. makeClusterPSOCK() now asserts cluster node functioning retrieving recording node’s session information including process ID corresponding R process.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-5-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"parallelly 1.5.0","text":"Help makeClusterPSOCK() gained detailed descriptions arguments defaults .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-4-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.4.0","text":"default values arguments ‘connectTimeout’ ‘timeout’ makeNodePSOCK() can now controlled via global options.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"deprecated-and-defunct-1-4-0","dir":"Changelog","previous_headings":"","what":"Deprecated and Defunct","title":"parallelly 1.4.0","text":"availableCores(method = “mc.cores”) now defunct favor “mc.cores+1”.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.3.0","text":"makeClusterPSOCK() treats workers refer local machine local canonical hostname “localhost”. avoids launch workers SSH, may supported systems / compute cluster. Added availableWorkers(). default returns localhost workers according availableCores(). addition, detects common HPC allocations given environment variables set HPC scheduler. Option ‘future.availableCores.fallback’, defaults environment variable ‘R_FUTURE_AVAILABLECORES_FALLBACK’ can now used specify default number cores / workers returned availableCores() availableWorkers() settings available. instance, R_FUTURE_AVAILABLECORES_FALLBACK=1 set system wide HPC environment, R processes uses availableCores() detect many cores can used run single-core processes. Without fallback setting, without core-specifying settings, default use cores machine, play well multi-user systems.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-3-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.3.0","text":"Creation cluster futures (including multisession ones) time already 40 seconds workers busy. New default timeout 30 days (option ‘future.wait.timeout’). availableCores(methods = “_R_CHECK_LIMIT_CORES_”) give error running R CMD check.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.2.0","text":"Added makeClusterPSOCK() - version parallel::makePSOCKcluster() allows flexible control PSOCK cluster workers set launched communicated running external machines. Added generic .cluster() coercing objects cluster objects used plan(cluster, workers = .cluster(x)). Also added c() implementation cluster objects multiple cluster objects can combined single one.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-2-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.2.0","text":"Argument ‘user’ remote() ignored (since 1.1.0).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-1-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 1.1.1","text":"special case ‘remote’ futures use workers = “localhost” () use exact R executable main / calling R session (cases uses whatever ‘Rscript’ found PATH). already indeed implemented 1.0.1, added support reverse SSH tunnels 1.1.0 default behavior lost.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 1.1.0","text":"REMOTE CLUSTERS: now simple use cluster() remote() connect remote clusters / machines. long can connect via ssh machines, works also future. new code completely avoids incoming firewall incoming port forwarding issues previously needed. done using reverse SSH tunneling. also need worry internal external IP numbers.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-0-15-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 0.15.0","text":"Now availableCores() also acknowledges environment variable NSLOTS set Sun/Oracle Grid Engine (SGE).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-0-12-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"parallelly 0.12.0","text":"FIX: Now availableCores() returns 3L (=2L+1L) instead 2L _R_CHECK_LIMIT_CORES_ set.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-0-10-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 0.10.0","text":"Now availableCores() also acknowledges number CPUs allotted Slurm.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"parallelly 0.8.0","text":"availableCores(“mc.cores”) returns getOption(“mc.cores”) + 1L, option ‘mc.cores’ specifies “allowed number _additional_ R processes” used addition main R process.","code":""}]
